{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, sys, regex\n",
    "import torch\n",
    "import GPUtil\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "##----------------------------------------------------\n",
    "from keras.models import load_model\n",
    "from transformers import *\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers import XLMRobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, XLMRobertaModel\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from preprocessing import preprocess,preprocess_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading tokenizer for LSTM and GRU\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the MARBERT tokenizer\n",
    "MARBERT_tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocess(\"2018-E-c-Ar-dev.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess your dataset\n",
    "x_test = df_test[\"Tweet\"].tolist()\n",
    "y_test_pre = df_test.drop([\"ID\",\"Tweet\"],axis=1)\n",
    "y_test = np.asarray(y_test_pre.values.tolist())\n",
    "xtest_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the MARBERT model for multi-label classification\n",
    "MARBERT_model = AutoModelForSequenceClassification.from_pretrained(\"UBC-NLP/MARBERT\", num_labels=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the MARBERT model for multi-label classification\n",
    "MARBERT_model = AutoModelForSequenceClassification.from_pretrained(\"UBC-NLP/MARBERT\", num_labels=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "MARBERT_model.load_state_dict(torch.load(\"marbert_4epochs.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marbert_predict(sentence, probs=False):\n",
    "    encoded_input = MARBERT_tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Move the input tensors to the device\n",
    "    input_ids = encoded_input[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded_input[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    MARBERT_model.eval()\n",
    "\n",
    "    # Move the model to the device\n",
    "    MARBERT_model.to(device)\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = MARBERT_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    predictions = torch.round(probabilities)\n",
    "    probabilities = np.asarray(probabilities).astype('int32')[0].tolist()\n",
    "    predictions = np.asarray(predictions).astype('int32')[0].tolist()\n",
    "    if probs:\n",
    "        return probabilities\n",
    "    else:\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8569\n",
      "Precision: 0.7191\n",
      "Recall: 0.5505\n",
      "F1-Score: 0.6236\n"
     ]
    }
   ],
   "source": [
    "# Lists to store predicted and true labels\n",
    "all_predictions_mar = []\n",
    "\n",
    "for sentence in x_test:\n",
    "    all_predictions_mar.append(marbert_predict(sentence))\n",
    "\n",
    "\n",
    "trueN_mar = 0\n",
    "trueP_mar = 0\n",
    "falseN_mar = 0\n",
    "falseP_mar = 0\n",
    "# Calculate evaluation metrics\n",
    "for i in range(len(all_predictions_mar)):\n",
    "    for j in range(11):\n",
    "        if all_predictions_mar[i][j] == 0:\n",
    "            if y_test[i][j] == 0:\n",
    "                trueN_mar+=1\n",
    "            if y_test[i][j] == 1:\n",
    "                falseN_mar+=1\n",
    "        if all_predictions_mar[i][j] == 1:\n",
    "            if y_test[i][j] == 1:\n",
    "                trueP_mar+=1\n",
    "            if y_test[i][j] == 0:\n",
    "                falseP_mar+=1\n",
    "\n",
    "positive_mar = trueP_mar + falseN_mar\n",
    "negative_mar = trueN_mar + falseP_mar\n",
    "\n",
    "accuracy_mar = (trueN_mar + trueP_mar) / (positive_mar + negative_mar)\n",
    "f1score_mar = (2 * trueP_mar) / (2*trueP_mar + falseP_mar + falseN_mar)\n",
    "precision_mar = trueP_mar / (trueP_mar + falseP_mar)\n",
    "recall_mar = trueP_mar / (trueP_mar + falseN_mar)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_mar:.4f}\")\n",
    "print(f\"Precision: {precision_mar:.4f}\")\n",
    "print(f\"Recall: {recall_mar:.4f}\")\n",
    "print(f\"F1-Score: {f1score_mar:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model(\"LSTM_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 100\n",
    "VOCABULARY_SIZE = 22000\n",
    "MAX_LENGTH = 26\n",
    "OOV_TOK = '<OOV>'\n",
    "TRUNCATE_TYPE = 'post'\n",
    "PADDING_TYPE = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_pad = pad_sequences(xtest_sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(sentence,probs=False):\n",
    "    pred_temp = x_test.copy()\n",
    "    pred_temp[0] = sentence\n",
    "    sequences = tokenizer.texts_to_sequences(pred_temp)\n",
    "    pred_pad = pad_sequences(sequences,maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n",
    "    pred = lstm_model.predict(pred_pad,verbose=None)\n",
    "    prob = pred[0]\n",
    "    if probs:\n",
    "        return prob\n",
    "    else:\n",
    "        return np.round(prob).astype(\"int32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365\n",
      "Precision: 0.6564\n",
      "Recall: 0.5058\n",
      "F1-Score: 0.5713\n"
     ]
    }
   ],
   "source": [
    "all_predictions_lstm = []\n",
    "\n",
    "pred = lstm_model.predict(xtest_pad,verbose=None)\n",
    "for p in pred:\n",
    "    all_predictions_lstm.append(np.round(p).astype(\"int32\").tolist())\n",
    "\n",
    "\n",
    "trueP = 0\n",
    "falseP = 0\n",
    "trueN = 0\n",
    "falseN = 0\n",
    "\n",
    "for i in range(len(all_predictions_lstm)):\n",
    "    for j in range(11):\n",
    "        if all_predictions_lstm[i][j] == 0:\n",
    "            if y_test[i][j] == 0:\n",
    "                trueN+=1\n",
    "            if y_test[i][j] == 1:\n",
    "                falseN+=1\n",
    "        if all_predictions_lstm[i][j] == 1:\n",
    "            if y_test[i][j] == 1:\n",
    "                trueP+=1\n",
    "            if y_test[i][j] == 0:\n",
    "                falseP+=1\n",
    "\n",
    "positive = trueP + falseN\n",
    "negative = trueN + falseP\n",
    "\n",
    "accuracy = (trueN + trueP) / (positive + negative)\n",
    "f1score = (2 * trueP) / (2*trueP + falseP + falseN)\n",
    "precision = trueP / (trueP + falseP)\n",
    "recall = trueP / (trueP + falseN)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = load_model(\"GRU_Model_Final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_predict(sentence,probs=False):\n",
    "    pred_temp = x_test.copy()\n",
    "    pred_temp[0] = sentence\n",
    "    sequences = tokenizer.texts_to_sequences(pred_temp)\n",
    "    pred_pad = pad_sequences(sequences,maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n",
    "    pred = gru_model.predict(pred_pad,verbose=None)\n",
    "    prob = pred[0]\n",
    "    if probs:\n",
    "        return prob\n",
    "    else:\n",
    "        return np.round(prob).astype(\"int32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8246\n",
      "Precision: 0.7849\n",
      "Recall: 0.2554\n",
      "F1-Score: 0.3854\n"
     ]
    }
   ],
   "source": [
    "all_predictions_gru = []\n",
    "\n",
    "pred = gru_model.predict(xtest_pad,verbose=None)\n",
    "for p in pred:\n",
    "    all_predictions_gru.append(np.round(p).astype(\"int32\"))\n",
    "\n",
    "\n",
    "trueP_gru = 0\n",
    "falseP_gru = 0\n",
    "trueN_gru = 0\n",
    "falseN_gru = 0\n",
    "\n",
    "for i in range(len(all_predictions_gru)):\n",
    "    for j in range(11):\n",
    "        if all_predictions_gru[i][j] == 0:\n",
    "            if y_test[i][j] == 0:\n",
    "                trueN_gru+=1\n",
    "            if y_test[i][j] == 1:\n",
    "                falseN_gru+=1\n",
    "        if all_predictions_gru[i][j] == 1:\n",
    "            if y_test[i][j] == 1:\n",
    "                trueP_gru+=1\n",
    "            if y_test[i][j] == 0:\n",
    "                falseP_gru+=1\n",
    "\n",
    "positive_gru = trueP_gru + falseN_gru\n",
    "negative_gru = trueN_gru + falseP_gru\n",
    "\n",
    "accuracy_gru = (trueN_gru + trueP_gru) / (positive_gru + negative_gru)\n",
    "f1score_gru = (2 * trueP_gru) / (2*trueP_gru + falseP_gru + falseN_gru)\n",
    "precision_gru = trueP_gru / (trueP_gru + falseP_gru)\n",
    "recall_gru = trueP_gru / (trueP_gru + falseN_gru)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_gru:.4f}\")\n",
    "print(f\"Precision: {precision_gru:.4f}\")\n",
    "print(f\"Recall: {recall_gru:.4f}\")\n",
    "print(f\"F1-Score: {f1score_gru:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an ensemble layer as a weighted average layer of all probabilities from the 3 models. <br>\n",
    "We select weights in relation to F1 score: <br>\n",
    "    - Marbert: F1 score = 0.6236<br>\n",
    "    - LSTM:    F1 score = 0.5713<br>\n",
    "    - GRU:     F1 score = 0.3854<br>\n",
    "\n",
    "We will divide each F1 score by the sum of the f1 scores to get a weight for the model, with weights adding up to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.580343899743148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_f1 = f1score + f1score_gru + f1score_mar\n",
    "sum_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:  0.3615112783566524\n",
      "GRU:  0.24387792824845264\n",
      "MARBERT:  0.39461079339489485\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Model weights:\n",
    "lstm_weight = f1score / sum_f1\n",
    "gru_weight = f1score_gru / sum_f1\n",
    "marbert_weight = f1score_mar / sum_f1\n",
    "\n",
    "\n",
    "print(\"LSTM: \",lstm_weight)\n",
    "print(\"GRU: \",gru_weight)\n",
    "print(\"MARBERT: \",marbert_weight)\n",
    "print(\"Sum: \",gru_weight+lstm_weight+marbert_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(sentence,probs=False):\n",
    "    lstm_prob = lstm_predict(sentence,probs=True)\n",
    "    gru_prob = gru_predict(sentence,probs=True)\n",
    "    mar_prob = marbert_predict(sentence,probs=True)\n",
    "    lstm_prob = [i*lstm_weight for i in lstm_prob]\n",
    "    gru_prob = [i*gru_weight for i in gru_prob]\n",
    "    mar_prob = [i*marbert_weight for i in mar_prob]\n",
    "    probabilities = []\n",
    "    for i in range(len(lstm_prob)):\n",
    "        probabilities.append(lstm_prob[i] + gru_prob[i] + mar_prob[i])\n",
    "    if probs:\n",
    "        return probabilities\n",
    "    else:\n",
    "        return np.round(probabilities).astype(\"int32\").tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_preds = []\n",
    "mar_probs = []\n",
    "gru_preds = []\n",
    "lstm_preds = []\n",
    "\n",
    "for sentence in x_test:\n",
    "    mar_preds.append(marbert_predict(sentence))\n",
    "    mar_probs.append(marbert_predict(sentence,probs=True))\n",
    "\n",
    "lstm_probs = lstm_model.predict(xtest_pad,verbose = None)\n",
    "for p in lstm_probs:\n",
    "    lstm_preds.append(np.round(p).astype(\"int32\"))\n",
    "gru_probs = gru_model.predict(xtest_pad,verbose = None)\n",
    "for p in gru_probs:\n",
    "    gru_preds.append(np.round(p).astype(\"int32\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_weight = 0.23\n",
    "gru_weight = 0.32\n",
    "marbert_weight = 0.51\n",
    "ens_preds = np.zeros(np.asarray(mar_preds).shape)\n",
    "\n",
    "for i in range(len(mar_preds)):\n",
    "    for j in range(11):\n",
    "        ens_preds[i][j] = np.round(mar_preds[i][j]*marbert_weight + lstm_preds[i][j]*lstm_weight + gru_preds[i][j]*gru_weight).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ens_pred = np.zeros(np.asarray(all_predictions_mar2).shape)\n",
    "# for i in range(len(all_predictions_mar2)):\n",
    "#     for j in range(11):\n",
    "#         ens_pred[i][j] = np.round(ens_probs[i][j]).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8567\n",
      "Precision: 0.7028\n",
      "Recall: 0.5801\n",
      "F1-Score: 0.6356\n"
     ]
    }
   ],
   "source": [
    "trueN_ens = 0\n",
    "trueP_ens = 0\n",
    "falseN_ens = 0\n",
    "falseP_ens = 0\n",
    "# Calculate evaluation metrics\n",
    "for i in range(len(ens_preds)):\n",
    "    for j in range(11):\n",
    "        if ens_preds[i][j] == 0:\n",
    "            if y_test[i][j] == 0:\n",
    "                trueN_ens+=1\n",
    "            if y_test[i][j] == 1:\n",
    "                falseN_ens+=1\n",
    "        if ens_preds[i][j] == 1:\n",
    "            if y_test[i][j] == 1:\n",
    "                trueP_ens+=1\n",
    "            if y_test[i][j] == 0:\n",
    "                falseP_ens+=1\n",
    "\n",
    "positive_ens = trueP_ens + falseN_ens\n",
    "negative_ens = trueN_ens + falseP_ens\n",
    "\n",
    "accuracy_ens = (trueN_ens + trueP_ens) / (positive_ens + negative_ens)\n",
    "f1score_ens = (2 * trueP_ens) / (2*trueP_ens + falseP_ens + falseN_ens)\n",
    "precision_ens = trueP_ens / (trueP_ens + falseP_ens)\n",
    "recall_ens = trueP_ens / (trueP_ens + falseN_ens)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_ens:.4f}\")\n",
    "print(f\"Precision: {precision_ens:.4f}\")\n",
    "print(f\"Recall: {recall_ens:.4f}\")\n",
    "print(f\"F1-Score: {f1score_ens:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Ar-00289</td>\n",
       "      <td>ÿ®ÿßŸÇŸä ÿØŸÇÿßŸäŸÇ ŸàÿßÿÆŸÑÿµ ÿ≠ŸÑŸÇÿ© ÿ≥ŸÉŸàŸÑ ÿßŸÑÿ´ÿßŸÜŸäŸá ÿßŸÑŸÜÿ™ ŸÖÿ≥ÿ™ŸÑÿπŸÜ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Ar-02519</td>\n",
       "      <td>ŸÖÿπÿßŸÜÿßÿ© ŸäŸÉŸàŸÜ ÿØÿßŸäŸÖÿß ÿ°ÿ≠ÿ≥ÿßÿ≥ŸÉ ÿ®ŸÖÿ≠ŸÑŸá</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Ar-01952</td>\n",
       "      <td>ÿ¨ÿßÿ°ÿ≤Ÿá ÿßŸÉÿ´ÿ± ŸÖŸàÿ≥Ÿàÿ≥Ÿá ÿ™ÿÆÿßŸÅ ÿßŸÑÿßŸÖÿ±ÿßÿ∂ ŸÅÿ≤ÿ™ ÿ®Ÿáÿßÿß ÿßŸÜŸÜŸÜÿßÿßÿß</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Ar-02912</td>\n",
       "      <td>Ÿäÿ≥ÿ™ŸÅÿ≤ ÿ±ÿßÿ≠ÿ© ÿßŸÑÿ®ÿßŸÑ ÿßŸÑÿ∞ŸÉÿ±Ÿäÿßÿ™</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Ar-02756</td>\n",
       "      <td>ÿßŸÑŸÇŸÑÿ® ŸäÿßŸàŸÇÿ™ ŸàÿßŸÑŸÜŸÅÿ≥ ŸÖÿßŸáŸä ŸÖÿ±ÿ™ÿßÿ≠Ÿá ŸàŸÜÿ®ÿ∂ ÿßŸÑŸÇŸÑÿ® ŸÖÿßŸáŸà...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  anger  \\\n",
       "0  2018-Ar-00289    ÿ®ÿßŸÇŸä ÿØŸÇÿßŸäŸÇ ŸàÿßÿÆŸÑÿµ ÿ≠ŸÑŸÇÿ© ÿ≥ŸÉŸàŸÑ ÿßŸÑÿ´ÿßŸÜŸäŸá ÿßŸÑŸÜÿ™ ŸÖÿ≥ÿ™ŸÑÿπŸÜ       1   \n",
       "1  2018-Ar-02519                    ŸÖÿπÿßŸÜÿßÿ© ŸäŸÉŸàŸÜ ÿØÿßŸäŸÖÿß ÿ°ÿ≠ÿ≥ÿßÿ≥ŸÉ ÿ®ŸÖÿ≠ŸÑŸá       0   \n",
       "2  2018-Ar-01952   ÿ¨ÿßÿ°ÿ≤Ÿá ÿßŸÉÿ´ÿ± ŸÖŸàÿ≥Ÿàÿ≥Ÿá ÿ™ÿÆÿßŸÅ ÿßŸÑÿßŸÖÿ±ÿßÿ∂ ŸÅÿ≤ÿ™ ÿ®Ÿáÿßÿß ÿßŸÜŸÜŸÜÿßÿßÿß       0   \n",
       "3  2018-Ar-02912                        Ÿäÿ≥ÿ™ŸÅÿ≤ ÿ±ÿßÿ≠ÿ© ÿßŸÑÿ®ÿßŸÑ ÿßŸÑÿ∞ŸÉÿ±Ÿäÿßÿ™        1   \n",
       "4  2018-Ar-02756  ÿßŸÑŸÇŸÑÿ® ŸäÿßŸàŸÇÿ™ ŸàÿßŸÑŸÜŸÅÿ≥ ŸÖÿßŸáŸä ŸÖÿ±ÿ™ÿßÿ≠Ÿá ŸàŸÜÿ®ÿ∂ ÿßŸÑŸÇŸÑÿ® ŸÖÿßŸáŸà...      0   \n",
       "\n",
       "   anticipation  disgust  fear  joy  love  optimism  pessimism  sadness  \\\n",
       "0             0        1     0    1     0         0          1        0   \n",
       "1             0        0     0    0     0         0          0        1   \n",
       "2             0        0     1    0     0         0          1        0   \n",
       "3             0        0     0    0     0         0          0        1   \n",
       "4             0        0     1    0     0         0          0        1   \n",
       "\n",
       "   surprise  trust  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    classes = ensemble_predict(sentence)\n",
    "    class_labels = ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']\n",
    "    final = {}\n",
    "    for i,label in enumerate(class_labels):\n",
    "        final[label] = classes[i]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 1, 'love': 0, 'optimism': 0, 'pessimism': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ÿßÿ∂ÿ≠ŸÉ Ÿà ÿßŸÑÿ∂ÿ≠ŸÉÿ© Ÿáÿ™ÿ®ŸÇŸä ÿ∂ÿ≠ŸÉÿ™ŸäŸäŸÜ Ÿà ÿßÿ™ŸÜŸäŸÜ ŸÅ ÿßÿ™ŸÜŸäŸÜ ŸÅ ÿßÿ™ŸÜŸäŸÜ ÿ∂ÿ≠ŸÉ ŸÉŸÑ ÿßŸÑÿπÿßŸäÿ¥ŸäŸÜ ŸÉŸÑŸÜÿß ŸÅ ŸÖÿ±ŸÉÿ® Ÿàÿßÿßÿ≠ÿØÿ© ŸÖŸÉŸÖŸÑŸäŸÜ Ÿà ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ≠ŸÑŸàÿ© ÿ®ÿ™ÿßÿßÿÆÿØ ŸÅ ÿ´ÿßŸÜŸäÿ™ŸäŸäŸÜ üòâ üåπ\"\n",
    "print(get_labels(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 1, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 0, 'love': 0, 'optimism': 0, 'pessimism': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ÿßŸÜÿ™Ÿà ÿ¥ÿ±ŸÉŸá ÿ®ŸÜÿ™ ÿ≥ÿ™ŸäŸÜ ŸÉŸÑÿ® ÿßŸÑŸÖÿµÿ±ŸäŸá ŸÑŸÑÿßÿ™ÿµÿßŸÑÿßÿ™\\nüò°\"\n",
    "print(get_labels(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'love': 0, 'optimism': 0, 'pessimism': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ÿ£ÿ®ÿ∑ŸÑ ÿÆŸàŸÅ ŸÖŸÜ ŸÉŸÑ ÿ¥Ÿä ÿ£ŸÑÿß ÿÆŸàŸÅŸä ÿπŸÑŸâ ÿßÿ®ŸàŸä ŸÖŸÜ ÿßŸÑÿ£ŸäÿßŸÖ :(\"\n",
    "print(get_labels(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88033ea6e6aaf353f3d26ef69434bb9b1f089d6b00d896155ae24c39a5d92896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
