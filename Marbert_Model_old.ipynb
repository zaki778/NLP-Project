{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IDBV9z3XGK2P"},"outputs":[],"source":["# To show prompt asking for uploading the requirements.txt from disk\n","from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_O4IOQu6GnKq"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGoUAFQDHuGE"},"outputs":[],"source":["!pip install GPUtil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnDJHS5mH81o"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvjB6f0LIOkb"},"outputs":[],"source":["!pip install pytorch_pretrained_bert"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":323,"status":"ok","timestamp":1684788125246,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"GJow2fCA-ECG"},"outputs":[],"source":["import json, sys, regex\n","import torch\n","import GPUtil\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n","##----------------------------------------------------\n","from transformers import *\n","from transformers import XLMRobertaConfig\n","from transformers import XLMRobertaModel\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, XLMRobertaModel\n","from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import AutoTokenizer, AutoModel\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from preprocessing import preprocess\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"IXd8ERH0OMDH"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.29.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n","loading file vocab.txt from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\vocab.txt\n","loading file tokenizer.json from cache at None\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\special_tokens_map.json\n","loading file tokenizer_config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\tokenizer_config.json\n","loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.29.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n","loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.29.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n","loading configuration file config.json from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.29.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n","loading weights file pytorch_model.bin from cache at C:\\Users\\ahmed/.cache\\huggingface\\hub\\models--UBC-NLP--MARBERT\\snapshots\\88e1fa192dd723cf0b3563500aec46209762eb22\\pytorch_model.bin\n","Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load the MARBERT tokenizer\n","MARBERT_tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERT\")\n","\n","# Load the MARBERT model for multi-label classification\n","MARBERT_model = AutoModelForSequenceClassification.from_pretrained(\"UBC-NLP/MARBERT\", num_labels=11)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1238,"status":"ok","timestamp":1684806029832,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"wIwgjQoJPb6t"},"outputs":[],"source":["dataset_train_raw = preprocess(\"2018-E-c-Ar-train.xlsx\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1684806032929,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"Sc0J17NhQTY7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["# Preprocess your dataset\n","texts_train = dataset_train_raw[\"Tweet\"].tolist()\n","\n","encoded_inputs_train = MARBERT_tokenizer(texts_train, padding=True, truncation=True, return_tensors=\"pt\")\n","labels_train = dataset_train_raw.iloc[:, 2:].values  # Labels start from the third column"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1684806037850,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"_O02IBKXOVmv"},"outputs":[],"source":["# Convert the labels to tensors\n","labels_train = torch.tensor(labels_train, dtype=torch.float)\n","\n","# Create a TensorDataset from the encoded inputs and labels\n","dataset_train = TensorDataset(encoded_inputs_train.input_ids, encoded_inputs_train.attention_mask, labels_train)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1684806588592,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"gK6YKeAoQoFC","outputId":"5570d7ad-1158-4732-ac3d-6dc36581a822"},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of dataset_train: 2278\n","Shape of input_ids tensor in dataset_train: torch.Size([2278, 41])\n","Shape of attention_mask tensor in dataset_train: torch.Size([2278, 41])\n","Shape of labels tensor in dataset_train: torch.Size([2278, 11])\n"]}],"source":["print(\"Length of dataset_train:\", len(dataset_train))\n","print(\"Shape of input_ids tensor in dataset_train:\", dataset_train.tensors[0].shape)\n","print(\"Shape of attention_mask tensor in dataset_train:\", dataset_train.tensors[1].shape)\n","print(\"Shape of labels tensor in dataset_train:\", dataset_train.tensors[2].shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"VkYBYabWRBPF"},"outputs":[],"source":["# Define hyperparameters and optimizer\n","batch_size = 16\n","num_epochs = 20\n","learning_rate = 3e-5\n","optimizer = AdamW(MARBERT_model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684789300155,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"Qs-SxvyqRH27"},"outputs":[],"source":["# Create a DataLoader for the training dataset\n","dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6544321,"status":"ok","timestamp":1684797386634,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"PPCGe_1dOH8-","outputId":"648e382a-e3a1-488c-c367-c907be5894a6"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12536\\4211646582.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n","\u001b[1;32mc:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Perform training\n","MARBERT_model.train()\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    \n","    for batch in dataloader_train:\n","        # Retrieve the batch inputs and labels\n","        input_ids, attention_mask, batch_labels = batch\n","        \n","        # Clear gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        outputs = MARBERT_model(input_ids=input_ids, attention_mask=attention_mask, labels=batch_labels)\n","        loss = outputs.loss\n","        \n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Update total loss\n","        total_loss += loss.item()\n","    \n","    # Print average loss for the epoch\n","    average_loss = total_loss / len(dataloader_train)\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {average_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14068,"status":"ok","timestamp":1684797794896,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"-4bmhR_8xUn1","outputId":"58494937-1dc3-4b74-9b76-d28954cf7046"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684798482235,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"JK6Srr1XzqDf"},"outputs":[],"source":["model_save_name = 'marbert_16_10_2e-5.pt'\n","path = F\"/content/drive/MyDrive/GUC/Semester 10/NLP/Project/{model_save_name}\" "]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":11216,"status":"ok","timestamp":1684798502268,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"E1Ioe4eiwhJY"},"outputs":[],"source":["# Saving the trained model\n","torch.save(MARBERT_model.state_dict(), path)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1684798298389,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"prhTyO5uzc70","outputId":"ff91fbf1-4a52-4a99-86b1-c93c85aea7a2"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_9156f14c-5094-4130-9aa4-8525c2db23e1\", \"checkpoint.pth\", 651482577)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["files.download('checkpoint.pth')"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3299,"status":"ok","timestamp":1684798668383,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"96TwPYXL0u1i","outputId":"6b38639a-ac04-4277-b066-015ce1311185"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# Load saved model\n","MARBERT_model.load_state_dict(torch.load(path))"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":898,"status":"ok","timestamp":1684803077488,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"tiUROwSt3ZDZ"},"outputs":[],"source":["test_file = dataset_path + \"/processed_data_test.xlsx\"\n","dataset_test_raw = pd.read_excel(train_file)"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":787,"status":"ok","timestamp":1684799855688,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"IhUGfd0R4OAH"},"outputs":[],"source":["# Preprocess your dataset\n","texts_test = dataset_test_raw[\"Tweet\"].tolist()\n","\n","encoded_inputs_test = MARBERT_tokenizer(texts_test, padding=True, truncation=True, return_tensors=\"pt\")\n","labels_test = dataset_test_raw.iloc[:, 2:].values  # Assuming labels start from the third column"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1684799865246,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"k-McWApn4Z3g"},"outputs":[],"source":["# Convert the labels to tensors\n","labels_test = torch.tensor(labels_test, dtype=torch.float)\n","\n","# Create a TensorDataset from the encoded inputs and labels\n","dataset_test = TensorDataset(encoded_inputs_test.input_ids, encoded_inputs_test.attention_mask, labels_test)"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":971,"status":"ok","timestamp":1684799880590,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"h-kXdZzj4mNM"},"outputs":[],"source":["# Create a DataLoader for the test dataset\n","\n","dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214714,"status":"ok","timestamp":1684800097757,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"2ZLiPewq5Cwo","outputId":"e44e4098-7fed-456c-ac2c-15d63d1447e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9508\n","Precision: 0.9960\n","Recall: 0.9783\n","F1-Score: 0.9851\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Lists to store predicted and true labels\n","all_predictions = []\n","all_true_labels = []\n","\n","# Disable gradient calculation\n","with torch.no_grad():\n","    # Set the model to evaluation mode\n","    MARBERT_model.eval()\n","\n","    # Iterate over the test dataloader\n","    for batch in dataloader_test:\n","        # Retrieve the batch inputs and labels\n","        input_ids, attention_mask, batch_labels = batch\n","\n","        # Move the batch tensors to the device\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        batch_labels = batch_labels.to(device)\n","\n","        # Forward pass\n","        outputs = MARBERT_model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","\n","        # Convert logits to probabilities\n","        probabilities = torch.sigmoid(logits)\n","\n","        # Convert probabilities to predicted labels (0 or 1)\n","        predictions = torch.round(probabilities)\n","\n","        # Append predictions and true labels to the lists\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_true_labels.extend(batch_labels.cpu().numpy())\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(all_true_labels, all_predictions)\n","precision = precision_score(all_true_labels, all_predictions, average='weighted')\n","recall = recall_score(all_true_labels, all_predictions, average='weighted')\n","f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1-Score: {f1:.4f}\")\n"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":228825,"status":"ok","timestamp":1684804294018,"user":{"displayName":"Mohamed Zaki Abdelgawad","userId":"04211631937770322999"},"user_tz":-180},"id":"rWVQDTVPJW0B"},"outputs":[],"source":["# Looping on all test sentences and showing the output probabilities.\n","# Set the device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Specify the output file path\n","output_file = \"predicted_probabilities.txt\"\n","\n","test_sentences = dataset_test_raw[\"Tweet\"].tolist()\n","\n","# Open the output file in write mode\n","with open(output_file, \"w\") as file:\n","    for sentence in test_sentences:\n","        file.write(\"******************************************************************\\n\")\n","        file.write(f\"________________{sentence}____________________\\n\")\n","\n","        # Tokenize the sentence\n","        encoded_input = MARBERT_tokenizer.encode_plus(\n","            sentence,\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Move the input tensors to the device\n","        input_ids = encoded_input[\"input_ids\"].to(device)\n","        attention_mask = encoded_input[\"attention_mask\"].to(device)\n","\n","        # Set the model to evaluation mode\n","        MARBERT_model.eval()\n","\n","        # Move the model to the device\n","        MARBERT_model.to(device)\n","\n","        # Disable gradient calculation\n","        with torch.no_grad():\n","            # Forward pass\n","            outputs = MARBERT_model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","        # Convert logits to probabilities\n","        probabilities = torch.sigmoid(logits)\n","\n","        label_names = [\"anger\",\"anticipation\",\"disgust\",\"fear\",\"joy\",\"love\",\"optimism\",\"pessimism\",\"sadness\",\"surprise\",\"trust\"]  \n","\n","        # Write the predicted probabilities for each label to the file\n","        for i, label_name in enumerate(label_names):\n","            file.write(f\"{label_name}: {probabilities[0][i].item():.4f}\\n\")\n","            \n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOrVati0sPu1EX8E6o5JU8Y","gpuType":"T4","mount_file_id":"1cONor9fUyskbCOwDJvnnFVYoaX7mCmtL","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"88033ea6e6aaf353f3d26ef69434bb9b1f089d6b00d896155ae24c39a5d92896"}}},"nbformat":4,"nbformat_minor":0}
